{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e10d334c-1b7a-4470-8754-7ac6da6b9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1e17f56-d51e-4970-9264-855df496aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "BATCH_SIZE = 9\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 0\n",
    "OUTPUT_SEQUENCE_LENGTH = 16000\n",
    "SUBSET = 'both'\n",
    "NUM_LABELS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7385012-00c6-44f2-90d3-25b6759cdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "  audio = tf.squeeze(audio, axis=-1)\n",
    "  return audio, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46437839-58c9-46e5-9d81-d8bc5d052fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  # Getting the spectogram\n",
    "  spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b62f4480-ff46-481e-b063-ddf82bd6c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spec_ds(ds):\n",
    "  return ds.map(\n",
    "      map_func=lambda audio,label: (spectrogram(audio), label),\n",
    "      num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c77b4b24-81a2-4ced-8dc2-dc45af163d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep():\n",
    "    train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    seed=0,\n",
    "    output_sequence_length=OUTPUT_SEQUENCE_LENGTH,\n",
    "    subset=SUBSET)\n",
    "\n",
    "    label_names = np.array(train_ds.class_names)    \n",
    "\n",
    "    train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "\n",
    "    test_ds = val_ds.shard(num_shards=2, index=0)\n",
    "    val_ds = val_ds.shard(num_shards=2, index=1)\n",
    "\n",
    "    train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "    val_spectrogram_ds = make_spec_ds(val_ds)\n",
    "    test_spectrogram_ds = make_spec_ds(test_ds)\n",
    "\n",
    "    for spectrograms_, spect_labels_ in train_spectrogram_ds.take(1):\n",
    "      break\n",
    "\n",
    "    input_shape = spectrograms_.shape[1:]\n",
    "\n",
    "    return train_spectrogram_ds,val_spectrogram_ds,test_spectrogram_ds,label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88d1e847-ec2f-4da5-8c29-6545e16db71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 111 files belonging to 5 classes.\n",
      "Using 89 files for training.\n",
      "Using 22 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_spectrogram_ds,val_spectrogram_ds,test_spectrogram_ds,label_names = data_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59cac46f-0eed-4153-a089-f4e5348e0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop():\n",
    "    train_spectrogram_ds,val_spectrogram_ds,test_spectrogram_ds,label_names = data_prep()\n",
    "    \n",
    "    # Instantiate the `tf.keras.layers.Normalization` layer.\n",
    "    norm_layer = layers.Normalization()\n",
    "    # Fit the state of the layer to the spectrograms\n",
    "    # with `Normalization.adapt`.\n",
    "    norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "\n",
    "    for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
    "      break\n",
    "\n",
    "    input_shape = example_spectrograms.shape[1:]\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        # Downsample the input.\n",
    "        layers.Resizing(32, 32),\n",
    "        # Normalize.\n",
    "        norm_layer,\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_LABELS),\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    EPOCHS = 10\n",
    "    history = model.fit(\n",
    "        train_spectrogram_ds,\n",
    "        validation_data=val_spectrogram_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    "    )\n",
    "\n",
    "    return model,history,label_names\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9493f981-6c93-473f-baf5-619891c3f6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 111 files belonging to 5 classes.\n",
      "Using 89 files for training.\n",
      "Using 22 files for validation.\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 89ms/step - loss: 1.6099 - accuracy: 0.2697 - val_loss: 1.2123 - val_accuracy: 0.4444\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 64ms/step - loss: 1.4233 - accuracy: 0.3933 - val_loss: 1.1258 - val_accuracy: 0.5556\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 61ms/step - loss: 1.2890 - accuracy: 0.4270 - val_loss: 1.0973 - val_accuracy: 0.4444\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 1.2165 - accuracy: 0.5169 - val_loss: 1.0139 - val_accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 1.0931 - accuracy: 0.5955 - val_loss: 0.9148 - val_accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 61ms/step - loss: 1.0832 - accuracy: 0.5730 - val_loss: 0.9202 - val_accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 66ms/step - loss: 0.9402 - accuracy: 0.6742 - val_loss: 0.9273 - val_accuracy: 0.7778\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "model,history,label_names = training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8188d-3e22-42fd-9cb6-8daef4689302",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1ac7ca9-d294-4ceb-a0cf-aba8b2661184",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('forest_cnn_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5c823e5-8c3f-4a2c-a1ac-bc22496e36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('forest_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b929697-2efb-4372-bb47-3172504b91fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chainsaw', 'chirping_birds', 'crackling_fire', 'engine',\n",
       "       'footsteps'], dtype='<U14')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31356c8f-370c-4d40-802f-951f8846709a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
